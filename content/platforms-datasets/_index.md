---
title: "Platforms & Datasets"
draft: false
layout: "list"
tags: []
toc: false
socialShare: false
platforms:
  - title: "Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology"
    venue: "ICLR 2025"
    content: "We present a comprehensive platform for UAV vision-language navigation that bridges the gap between simulation and real-world deployment. Our benchmark provides realistic scenarios and evaluation metrics for advancing autonomous UAV systems."
    highlights:
      - key: "Platform"
        value: "Comprehensive simulation and real-world testing environment for UAV navigation"
      - key: "Benchmark"
        value: "Realistic scenarios with standardized evaluation metrics"
      - key: "Methodology"
        value: "Novel approach bridging sim-to-real gap in vision-language navigation"
    authors: "Xiangyu Wang, Donglin Yang, Ziqin Wang, Hohin Kwan, Jinyu Chen, Wenjun Wu, Hongsheng Li, Yue Liao, Si Liu"
    image: "/plat_data/openuav.png"
    link: "https://arxiv.org/abs/2410.07087"
    type: "image"
  - title: "VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection"
    venue: "CVPR 2025"
    content: "A large-scale dataset designed for fine-grained video reasoning through chain-of-thought methodology. We introduce core frame selection techniques to enhance video understanding and reasoning capabilities."
    highlights:
      - key: "Dataset Scale"
        value: "Large-scale collection with diverse video scenarios and reasoning tasks"
      - key: "Chain-of-Thought"
        value: "Structured reasoning methodology for fine-grained video understanding"
      - key: "Core Frame Selection"
        value: "Novel technique to identify and leverage key frames for efficient reasoning"
    authors: "Songhao Han, Wei Huang, Hairong Shi, Le Zhuo, Xiu Su, Shifeng Zhang, Xu Zhou, Xiaojuan Qi, Yue Liao, Si Liu"
    image: "/plat_data/videoespresso.png"
    link: "https://arxiv.org/pdf/2411.14794"
    type: "image"
  - title: "LLaVA-ST: A Multimodal Large Language Model for Fine-Grained Spatial-Temporal Understanding"
    venue: "CVPR 2025"
    content: "A multimodal large language model specifically designed for fine-grained spatial-temporal understanding. LLaVA-ST enables precise comprehension of complex spatial and temporal relationships in visual content."
    highlights:
      - key: "Multimodal Architecture"
        value: "Advanced integration of vision and language for spatial-temporal reasoning"
      - key: "Fine-Grained Understanding"
        value: "Precise comprehension of complex spatial and temporal relationships"
      - key: "Applications"
        value: "Enhanced performance in video understanding and visual question answering"
    authors: "Hongyu Li, Jinyu Chen, Ziyu Wei, Shaofei Huang, Tianrui Hui, Jialin Gao, Xiaoming Wei, Si Liu"
    image: "/plat_data/LLaVA-ST.png"
    link: "https://arxiv.org/abs/2501.08282"
    type: "image"
  - title: "Video2BEV: Transforming Drone Videos to BEVs for Video-based Geo-localization"
    venue: "ICCV 2025"
    content: "We transform drone videos into bird's-eye-view representations for improved geo-localization. This approach enables accurate spatial understanding and localization from aerial video footage."
    highlights:
      - key: "BEV Transformation"
        value: "Novel method to convert drone videos into bird's-eye-view representations"
      - key: "Geo-localization"
        value: "Accurate spatial understanding and localization from aerial footage"
      - key: "Video-based Approach"
        value: "Leverages temporal information for robust localization performance"
    authors: "Hao Ju, Shaofei Huang, Si Liu, Zhedong Zheng"
    image: "/plat_data/Video2BEV.png"
    link: "https://arxiv.org/abs/2411.13610"
    type: "image"
  - title: "AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation"
    venue: "ACM MM 2025"
    content: "An innovative dual-system approach for UAV-based vision and language navigation. AeroDuo combines visual perception with natural language understanding to enable intuitive UAV control and navigation."
    highlights:
      - key: "Dual-System Design"
        value: "Innovative architecture combining visual and linguistic processing"
      - key: "Vision-Language Integration"
        value: "Seamless fusion of visual perception and natural language understanding"
      - key: "Intuitive Control"
        value: "Natural language commands for user-friendly UAV navigation"
    authors: "Ruipu Wu, Yige Zhang, Jinyu Chen, Linjiang Huang, Shifeng Zhang, Xu Zhou, Liang Wang, Si Liu"
    image: "/plat_data/AeroDuo.png"
    link: "https://arxiv.org/abs/2508.15232"
    type: "image"
  - title: "RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation"
    venue: "NeurIPS 2025"
    content: "A comprehensive benchmark for evaluating long-horizon robotic manipulation tasks. RoboCerebra provides standardized evaluation protocols and diverse scenarios to advance research in embodied AI and robotics."
    highlights:
      - key: "Large-scale Benchmark"
        value: "Comprehensive evaluation framework for long-horizon robotic manipulation"
      - key: "Standardized Protocols"
        value: "Consistent evaluation metrics and methodologies across diverse scenarios"
      - key: "Research Advancement"
        value: "Advances embodied AI and robotics research through systematic evaluation"
    authors: "Songhao Han, Boxiang Qiu, Yue Liao, Siyuan Huang, Chen Gao, Shuicheng Yan, Si Liu"
    image: "/plat_data/robocerebra.png"
    link: "https://arxiv.org/html/2506.06677v1"
    type: "image"
  - title: "Hi AirStar: Guide Me to the Badminton Court"
    venue: "ACM MM demo 2025"
    content: "An interactive demonstration system that guides users to specific locations using natural language commands. This demo showcases practical applications of vision-language navigation in real-world scenarios."
    highlights:
      - key: "Interactive System"
        value: "Real-time guidance through natural language interaction"
      - key: "Practical Application"
        value: "Demonstrates vision-language navigation in real-world settings"
      - key: "User Experience"
        value: "Intuitive location guidance with conversational interface"
    authors: "Ziqin Wang, Jinyu Chen, Xiangyi Zheng, Qinan Liao, Linjiang Huang, Si Liu"
    video: "/plat_data/mmdemo.mp4"
    link: "https://arxiv.org/abs/2507.04430"
    type: "video"
---

